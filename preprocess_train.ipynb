{"cells":[{"cell_type":"markdown","metadata":{"id":"o5V0dBaR9k3z"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":76771,"status":"ok","timestamp":1718143127016,"user":{"displayName":"Raphael Rialland","userId":"15161041091141645294"},"user_tz":-120},"id":"WWjARAR0iVVq","outputId":"f09097b5-0d89-4133-94a6-35154510c6aa"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"KgYov6sShS4R"},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow.keras as k"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"nZQVcKzeHRcO"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"ldE1u1_wLSlM"},"outputs":[],"source":["# # set train dir origin\n","# dir_data_gdrive = \"/content/gdrive/MyDrive/coursework/p_final_project/project_02/data/sampled\"\n","# !cp -r \"/content/gdrive/MyDrive/coursework/p_final_project/project_02/data/sampled\" \"/content/data\"\n","# dir_data = \"/content/data\""]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["dir_data = r\"C:\\Users\\rapha\\My Drive\\Work\\jedha_dsfs\\coursework\\p_final_project\\project_02\\data\\eyes_only\""]},{"cell_type":"code","execution_count":14,"metadata":{"id":"uZ67BfrwBIpS"},"outputs":[],"source":["BATCH_SIZE = 64\n","IMAGE_SIZE = (86, 86)\n","MODEL_INPUT = IMAGE_SIZE + (3,)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1718143228440,"user":{"displayName":"Raphael Rialland","userId":"15161041091141645294"},"user_tz":-120},"id":"zLRbuFDYILym","outputId":"31e5fbe9-463e-43bb-acb0-26f261b5c886"},"outputs":[{"name":"stdout","output_type":"stream","text":["Positive images: 24001\n","Negative images: 24001\n","Positive to negative ratio: 0.5\n"]}],"source":["import os\n","\n","dir_drowsy = os.path.join(dir_data, 'closed_eye')\n","dir_non_drowsy = os.path.join(dir_data, 'open_eye')\n","\n","files_drowsy = os.listdir(dir_drowsy)\n","files_non_drowsy = os.listdir(dir_non_drowsy)\n","\n","positive_count = len(files_drowsy)\n","negative_count = len(files_non_drowsy)\n","\n","print(f\"Positive images: {positive_count}\")\n","print(f\"Negative images: {negative_count}\")\n","print(f\"Positive to negative ratio: {round(positive_count/(positive_count + negative_count), 2)}\")"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"q7itb41cCLjJ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 38400 images belonging to 2 classes.\n","Found 9600 images belonging to 2 classes.\n"]}],"source":["\"\"\"\n","train_datagen = ImageDataGenerator(...,\n","                                   preprocessing_function=convert_grayscale_to_three_rank,\n","                                   ...)\n","\"\"\"\n","\n","def preprocess_data(image):\n","\n","    def convert_grayscale_to_three_rank(image):\n","        # Check if the image has a single channel (grayscale)\n","        if image.shape[-1] == 1:\n","            image = np.stack((image,)*3, axis=-1)\n","        \n","        return image\n","\n","    image = convert_grayscale_to_three_rank(image)\n","    image = k.applications.vgg16.preprocess_input(image)\n","    return image\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Add our data-augmentation parameters to ImageDataGenerator\n","train_datagen = ImageDataGenerator(\n","                                   rescale = 1./255.,\n","                                   rotation_range = 30,\n","                                   width_shift_range = 0.5,\n","                                   height_shift_range = 0.5,\n","                                   brightness_range = [0.8, 1.2],\n","                                   shear_range = 15,\n","                                   zoom_range = 0.3,\n","                                   horizontal_flip = True,\n","                                   preprocessing_function=preprocess_data,\n","                                   validation_split=0.2\n","                                   )\n","\n","train_datagen = ImageDataGenerator(\n","                                   rescale = 1./255.,\n","                                   rotation_range = 5,\n","                                   width_shift_range = 0.1,\n","                                   height_shift_range = 0.1,\n","                                   brightness_range = [0.95, 1.05],\n","                                   shear_range = 5,\n","                                   zoom_range = 0.1,\n","                                   horizontal_flip = True,\n","                                   preprocessing_function=preprocess_data,\n","                                   validation_split=0.2\n","                                   )\n","\n","# Flow training images in batches of BATCH_SIZE using train_datagen generator\n","train_generator = train_datagen.flow_from_directory(dir_data,\n","                                                    batch_size = BATCH_SIZE,\n","                                                    class_mode = 'binary',\n","                                                    target_size = IMAGE_SIZE,\n","                                                    color_mode='rgb',\n","                                                    subset='training',\n","                                                    shuffle=True)\n","\n","# Flow validation images in batches of BATCH_SIZE using test_datagen generator\n","validation_generator = train_datagen.flow_from_directory(dir_data,\n","                                                        batch_size = BATCH_SIZE,\n","                                                        class_mode = 'binary',\n","                                                        target_size = IMAGE_SIZE,\n","                                                        color_mode='rgb',\n","                                                        subset='validation',\n","                                                        shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"oN35l77H9odU"},"source":["# Model"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1747,"status":"ok","timestamp":1718143230185,"user":{"displayName":"Raphael Rialland","userId":"15161041091141645294"},"user_tz":-120},"id":"6tNvrAYEgoV0","outputId":"02d4ac24-dea2-4a65-e684-00f1e06212c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 86, 86, 3)]       0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 86, 86, 64)        1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 86, 86, 64)        36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 43, 43, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 43, 43, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 43, 43, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 21, 21, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 21, 21, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 21, 21, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 21, 21, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 10, 10, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 10, 10, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 10, 10, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 10, 10, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 5, 5, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 5, 5, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 5, 5, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 7,079,424\n","Non-trainable params: 7,635,264\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras.applications.vgg16 import VGG16\n","\n","base_model = VGG16(input_shape = MODEL_INPUT, # Shape of our images\n","include_top = False, # Leave out the last fully connected layer\n","weights = 'imagenet')\n","\n","fine_tune_amount = 4\n","\n","# Fine tuning\n","for layer in base_model.layers:\n","    if layer in base_model.layers[-fine_tune_amount:]:\n","        layer.trainable = True\n","    else:\n","        layer.trainable = False\n","\n","# No fine tuning\n","# base_model.trainable = False\n","\n","base_model.summary()"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ZEmzMqsngtUe"},"outputs":[],"source":["regularizer = k.regularizers.l2(0.1)\n","drop_rate = 0.2\n","\n","# Flatten to 1D using max pool or flatten\n","x = k.layers.GlobalAveragePooling2D()(base_model.output)\n","\n","x = k.layers.Dense(512, activation='swish',\n","                   kernel_regularizer=regularizer)(x)\n","\n","x = k.layers.BatchNormalization()(x)\n","x = k.layers.Dropout(drop_rate)(x)\n","\n","x = k.layers.Dense(256, activation='swish',\n","                   kernel_regularizer=regularizer)(x)\n","\n","x = k.layers.BatchNormalization()(x)\n","x = k.layers.Dropout(drop_rate)(x)\n","\n","x = k.layers.Dense(128, activation='swish',\n","                   kernel_regularizer=regularizer)(x)\n","\n","x = k.layers.BatchNormalization()(x)\n","x = k.layers.Dropout(drop_rate)(x)\n","\n","x = k.layers.Dense(64, activation='swish',\n","                   kernel_regularizer=regularizer)(x)\n","\n","# Classification layer\n","x = k.layers.Dense(1, activation='sigmoid')(x)\n","\n","model = tf.keras.models.Model(base_model.input, x)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# Define the exponential decay schedule\n","lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate=0.1,\n","    decay_steps=50,\n","    decay_rate=0.9,\n","    staircase=True  # If True, the learning rate decays at discrete intervals\n",")\n","\n","class LearningRateLogger(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        # Access the learning rate from the optimizer\n","        lr = self.model.optimizer.learning_rate\n","        if isinstance(lr, tf.keras.optimizers.schedules.LearningRateSchedule):\n","            # If the learning rate is a schedule, we get the learning rate value at the current step\n","            lr = lr(self.model.optimizer.iterations)\n","        else:\n","            # If it's a static learning rate, we get the learning rate value directly\n","            lr = lr\n","        lr_value = tf.keras.backend.get_value(lr)\n","        print(\"\\n\",f\"Epoch {epoch+1}, Learning Rate: {lr_value:.8f}\")\n","        \n","lr_logger = LearningRateLogger()\n","\n","earlystopper = k.callbacks.EarlyStopping(\n","    monitor='val_loss', \n","    mode='min', \n","    verbose=1, \n","    patience=10, \n","    restore_best_weights=True,\n","    )\n","\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","# Define the path where the checkpoints will be saved\n","checkpoint_path = r\"C:\\Users\\rapha\\My Drive\\Work\\jedha_dsfs\\coursework\\p_final_project\\project_02\\model_checkpoints\\model_checkpoint.keras\"\n","\n","# Create a ModelCheckpoint object\n","checkpoint = ModelCheckpoint(\n","    filepath=checkpoint_path,\n","    monitor='val_acc',\n","    mode='max',\n","    save_best_only=True,\n","    verbose=1,\n",")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["model.compile(\n","    optimizer = k.optimizers.Adam(learning_rate=lr_schedule),\n","    loss='binary_crossentropy',\n","    metrics=['acc'],\n","    )\n","\n","# model.summary()"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":498758,"status":"ok","timestamp":1718143728941,"user":{"displayName":"Raphael Rialland","userId":"15161041091141645294"},"user_tz":-120},"id":"DmHV6JC1gzOg","outputId":"d0578bcd-81d1-498b-ac05-46e5720fda27"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/40\n","100/100 [==============================] - ETA: 0s - loss: 3.5923 - acc: 0.9592\n","Epoch 1: val_acc improved from -inf to 0.83641, saving model to C:\\Users\\rapha\\My Drive\\Work\\jedha_dsfs\\coursework\\p_final_project\\project_02\\model_checkpoints\\model_checkpoint.keras\n","100/100 [==============================] - 53s 536ms/step - loss: 3.5923 - acc: 0.9592 - val_loss: 4.0211 - val_acc: 0.8364\n","Epoch 2/40\n","100/100 [==============================] - ETA: 0s - loss: 3.2799 - acc: 0.9683\n","Epoch 2: val_acc improved from 0.83641 to 0.90547, saving model to C:\\Users\\rapha\\My Drive\\Work\\jedha_dsfs\\coursework\\p_final_project\\project_02\\model_checkpoints\\model_checkpoint.keras\n","100/100 [==============================] - 46s 463ms/step - loss: 3.2799 - acc: 0.9683 - val_loss: 3.1598 - val_acc: 0.9055\n","Epoch 3/40\n","100/100 [==============================] - ETA: 0s - loss: 4.0427 - acc: 0.9744\n","Epoch 3: val_acc improved from 0.90547 to 0.92016, saving model to C:\\Users\\rapha\\My Drive\\Work\\jedha_dsfs\\coursework\\p_final_project\\project_02\\model_checkpoints\\model_checkpoint.keras\n","100/100 [==============================] - 43s 429ms/step - loss: 4.0427 - acc: 0.9744 - val_loss: 3.8475 - val_acc: 0.9202\n","Epoch 4/40\n","100/100 [==============================] - ETA: 0s - loss: 3.5987 - acc: 0.9720\n","Epoch 4: val_acc improved from 0.92016 to 0.92922, saving model to C:\\Users\\rapha\\My Drive\\Work\\jedha_dsfs\\coursework\\p_final_project\\project_02\\model_checkpoints\\model_checkpoint.keras\n","100/100 [==============================] - 43s 435ms/step - loss: 3.5987 - acc: 0.9720 - val_loss: 2.6501 - val_acc: 0.9292\n","Epoch 5/40\n","100/100 [==============================] - ETA: 0s - loss: 2.5660 - acc: 0.9800\n","Epoch 5: val_acc did not improve from 0.92922\n","100/100 [==============================] - 43s 432ms/step - loss: 2.5660 - acc: 0.9800 - val_loss: 2.4825 - val_acc: 0.7333\n","Epoch 6/40\n","100/100 [==============================] - ETA: 0s - loss: 1.9826 - acc: 0.9787\n","Epoch 6: val_acc did not improve from 0.92922\n","100/100 [==============================] - 40s 404ms/step - loss: 1.9826 - acc: 0.9787 - val_loss: 2.3905 - val_acc: 0.8159\n","Epoch 7/40\n","100/100 [==============================] - ETA: 0s - loss: 1.7015 - acc: 0.9856\n","Epoch 7: val_acc did not improve from 0.92922\n","100/100 [==============================] - 39s 389ms/step - loss: 1.7015 - acc: 0.9856 - val_loss: 1.7456 - val_acc: 0.8956\n","Epoch 8/40\n","100/100 [==============================] - ETA: 0s - loss: 1.5778 - acc: 0.9827\n","Epoch 8: val_acc did not improve from 0.92922\n","100/100 [==============================] - 38s 377ms/step - loss: 1.5778 - acc: 0.9827 - val_loss: 1.7069 - val_acc: 0.9016\n","Epoch 9/40\n","100/100 [==============================] - ETA: 0s - loss: 1.4414 - acc: 0.9816\n","Epoch 9: val_acc did not improve from 0.92922\n","100/100 [==============================] - 36s 361ms/step - loss: 1.4414 - acc: 0.9816 - val_loss: 2.1666 - val_acc: 0.8008\n","Epoch 10/40\n","100/100 [==============================] - ETA: 0s - loss: 1.3221 - acc: 0.9842\n","Epoch 10: val_acc did not improve from 0.92922\n","100/100 [==============================] - 36s 356ms/step - loss: 1.3221 - acc: 0.9842 - val_loss: 1.4005 - val_acc: 0.9239\n","Epoch 11/40\n","100/100 [==============================] - ETA: 0s - loss: 1.2283 - acc: 0.9848\n","Epoch 11: val_acc did not improve from 0.92922\n","100/100 [==============================] - 35s 348ms/step - loss: 1.2283 - acc: 0.9848 - val_loss: 1.4763 - val_acc: 0.8970\n","Epoch 12/40\n","100/100 [==============================] - ETA: 0s - loss: 1.1488 - acc: 0.9881\n","Epoch 12: val_acc did not improve from 0.92922\n","100/100 [==============================] - 34s 341ms/step - loss: 1.1488 - acc: 0.9881 - val_loss: 1.2637 - val_acc: 0.9239\n","Epoch 13/40\n","100/100 [==============================] - ETA: 0s - loss: 1.0801 - acc: 0.9847\n","Epoch 13: val_acc did not improve from 0.92922\n","100/100 [==============================] - 34s 339ms/step - loss: 1.0801 - acc: 0.9847 - val_loss: 1.5036 - val_acc: 0.8823\n","Epoch 14/40\n","100/100 [==============================] - ETA: 0s - loss: 1.0124 - acc: 0.9862\n","Epoch 14: val_acc did not improve from 0.92922\n","100/100 [==============================] - 33s 328ms/step - loss: 1.0124 - acc: 0.9862 - val_loss: 1.6925 - val_acc: 0.5778\n","Epoch 15/40\n","100/100 [==============================] - ETA: 0s - loss: 0.9713 - acc: 0.9850\n","Epoch 15: val_acc did not improve from 0.92922\n","100/100 [==============================] - 33s 329ms/step - loss: 0.9713 - acc: 0.9850 - val_loss: 1.1457 - val_acc: 0.9130\n","Epoch 16/40\n","100/100 [==============================] - ETA: 0s - loss: 0.9217 - acc: 0.9878\n","Epoch 16: val_acc did not improve from 0.92922\n","100/100 [==============================] - 32s 325ms/step - loss: 0.9217 - acc: 0.9878 - val_loss: 1.1815 - val_acc: 0.9078\n","Epoch 17/40\n","100/100 [==============================] - ETA: 0s - loss: 0.8983 - acc: 0.9883\n","Epoch 17: val_acc did not improve from 0.92922\n","100/100 [==============================] - 32s 320ms/step - loss: 0.8983 - acc: 0.9883 - val_loss: 1.3474 - val_acc: 0.7173\n","Epoch 18/40\n","100/100 [==============================] - ETA: 0s - loss: 0.8761 - acc: 0.9873\n","Epoch 18: val_acc did not improve from 0.92922\n","100/100 [==============================] - 32s 319ms/step - loss: 0.8761 - acc: 0.9873 - val_loss: 1.2472 - val_acc: 0.8811\n","Epoch 19/40\n","100/100 [==============================] - ETA: 0s - loss: 0.8582 - acc: 0.9850\n","Epoch 19: val_acc improved from 0.92922 to 0.92937, saving model to C:\\Users\\rapha\\My Drive\\Work\\jedha_dsfs\\coursework\\p_final_project\\project_02\\model_checkpoints\\model_checkpoint.keras\n","100/100 [==============================] - 32s 320ms/step - loss: 0.8582 - acc: 0.9850 - val_loss: 1.0076 - val_acc: 0.9294\n","Epoch 20/40\n","100/100 [==============================] - ETA: 0s - loss: 0.8355 - acc: 0.9864\n","Epoch 20: val_acc did not improve from 0.92937\n","100/100 [==============================] - 32s 316ms/step - loss: 0.8355 - acc: 0.9864 - val_loss: 1.0030 - val_acc: 0.9262\n","Epoch 21/40\n","100/100 [==============================] - ETA: 0s - loss: 0.8213 - acc: 0.9856\n","Epoch 21: val_acc did not improve from 0.92937\n","100/100 [==============================] - 31s 313ms/step - loss: 0.8213 - acc: 0.9856 - val_loss: 1.1740 - val_acc: 0.8945\n","Epoch 22/40\n","100/100 [==============================] - ETA: 0s - loss: 0.8031 - acc: 0.9867\n","Epoch 22: val_acc did not improve from 0.92937\n","100/100 [==============================] - 31s 314ms/step - loss: 0.8031 - acc: 0.9867 - val_loss: 1.0697 - val_acc: 0.9172\n","Epoch 23/40\n","100/100 [==============================] - ETA: 0s - loss: 0.7921 - acc: 0.9862\n","Epoch 23: val_acc did not improve from 0.92937\n","100/100 [==============================] - 31s 313ms/step - loss: 0.7921 - acc: 0.9862 - val_loss: 1.2365 - val_acc: 0.8891\n","Epoch 24/40\n","100/100 [==============================] - ETA: 0s - loss: 0.7841 - acc: 0.9853\n","Epoch 24: val_acc improved from 0.92937 to 0.93250, saving model to C:\\Users\\rapha\\My Drive\\Work\\jedha_dsfs\\coursework\\p_final_project\\project_02\\model_checkpoints\\model_checkpoint.keras\n","100/100 [==============================] - 27s 275ms/step - loss: 0.7841 - acc: 0.9853 - val_loss: 0.9235 - val_acc: 0.9325\n","Epoch 25/40\n","100/100 [==============================] - ETA: 0s - loss: 0.7716 - acc: 0.9845\n","Epoch 25: val_acc did not improve from 0.93250\n","100/100 [==============================] - 27s 271ms/step - loss: 0.7716 - acc: 0.9845 - val_loss: 0.9514 - val_acc: 0.9233\n","Epoch 26/40\n","100/100 [==============================] - ETA: 0s - loss: 0.7642 - acc: 0.9867\n","Epoch 26: val_acc did not improve from 0.93250\n","100/100 [==============================] - 28s 276ms/step - loss: 0.7642 - acc: 0.9867 - val_loss: 0.9881 - val_acc: 0.9172\n","Epoch 27/40\n","100/100 [==============================] - ETA: 0s - loss: 0.7576 - acc: 0.9866\n","Epoch 27: val_acc did not improve from 0.93250\n","100/100 [==============================] - 31s 313ms/step - loss: 0.7576 - acc: 0.9866 - val_loss: 1.0043 - val_acc: 0.9141\n","Epoch 28/40\n","100/100 [==============================] - ETA: 0s - loss: 0.7532 - acc: 0.9875\n","Epoch 28: val_acc did not improve from 0.93250\n","100/100 [==============================] - 31s 309ms/step - loss: 0.7532 - acc: 0.9875 - val_loss: 0.9922 - val_acc: 0.9217\n","Epoch 29/40\n","100/100 [==============================] - ETA: 0s - loss: 0.7489 - acc: 0.9870\n","Epoch 29: val_acc did not improve from 0.93250\n","100/100 [==============================] - 31s 307ms/step - loss: 0.7489 - acc: 0.9870 - val_loss: 0.9461 - val_acc: 0.9214\n","Epoch 30/40\n","100/100 [==============================] - ETA: 0s - loss: 0.7472 - acc: 0.9859\n","Epoch 30: val_acc did not improve from 0.93250\n","100/100 [==============================] - 31s 307ms/step - loss: 0.7472 - acc: 0.9859 - val_loss: 8.2538 - val_acc: 0.4981\n","Epoch 31/40\n","100/100 [==============================] - ETA: 0s - loss: 0.7419 - acc: 0.9869\n","Epoch 31: val_acc did not improve from 0.93250\n","100/100 [==============================] - 32s 323ms/step - loss: 0.7419 - acc: 0.9869 - val_loss: 1.0111 - val_acc: 0.9158\n","Epoch 32/40\n","100/100 [==============================] - ETA: 0s - loss: 0.7392 - acc: 0.9872\n","Epoch 32: val_acc did not improve from 0.93250\n","100/100 [==============================] - 31s 309ms/step - loss: 0.7392 - acc: 0.9872 - val_loss: 0.9248 - val_acc: 0.9286\n","Epoch 33/40\n","100/100 [==============================] - ETA: 0s - loss: 0.7379 - acc: 0.9861\n","Epoch 33: val_acc did not improve from 0.93250\n","100/100 [==============================] - 30s 298ms/step - loss: 0.7379 - acc: 0.9861 - val_loss: 1.0387 - val_acc: 0.9053\n","Epoch 34/40\n","100/100 [==============================] - ETA: 0s - loss: 0.7297 - acc: 0.9880\n","Epoch 34: val_acc did not improve from 0.93250\n","100/100 [==============================] - 28s 282ms/step - loss: 0.7297 - acc: 0.9880 - val_loss: 1.0361 - val_acc: 0.9094\n","Epoch 35/40\n","100/100 [==============================] - ETA: 0s - loss: 0.7306 - acc: 0.9881\n","Epoch 35: val_acc did not improve from 0.93250\n","100/100 [==============================] - 27s 270ms/step - loss: 0.7306 - acc: 0.9881 - val_loss: 1.0031 - val_acc: 0.9167\n","Epoch 36/40\n","100/100 [==============================] - ETA: 0s - loss: 0.7368 - acc: 0.9864\n","Epoch 36: val_acc did not improve from 0.93250\n","100/100 [==============================] - 27s 271ms/step - loss: 0.7368 - acc: 0.9864 - val_loss: 1.0231 - val_acc: 0.9111\n","Epoch 37/40\n","100/100 [==============================] - ETA: 0s - loss: 0.7312 - acc: 0.9862\n","Epoch 37: val_acc did not improve from 0.93250\n","100/100 [==============================] - 27s 273ms/step - loss: 0.7312 - acc: 0.9862 - val_loss: 1.0026 - val_acc: 0.9147\n","Epoch 38/40\n","100/100 [==============================] - ETA: 0s - loss: 0.7293 - acc: 0.9873\n","Epoch 38: val_acc did not improve from 0.93250\n","100/100 [==============================] - 27s 274ms/step - loss: 0.7293 - acc: 0.9873 - val_loss: 1.0254 - val_acc: 0.9105\n","Epoch 39/40\n","100/100 [==============================] - ETA: 0s - loss: 0.7233 - acc: 0.9894\n","Epoch 39: val_acc did not improve from 0.93250\n","100/100 [==============================] - 27s 273ms/step - loss: 0.7233 - acc: 0.9894 - val_loss: 1.0233 - val_acc: 0.9133\n","Epoch 40/40\n","100/100 [==============================] - ETA: 0s - loss: 0.7317 - acc: 0.9875\n","Epoch 40: val_acc did not improve from 0.93250\n","100/100 [==============================] - 27s 276ms/step - loss: 0.7317 - acc: 0.9875 - val_loss: 1.0890 - val_acc: 0.9008\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x2842e598b80>"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(\n","    train_generator,\n","    validation_data=validation_generator,\n","    steps_per_epoch=100,\n","    # validation_freq=5,\n","    validation_steps=100,\n","    callbacks=[checkpoint,\n","    # earlystopper, lr_logger,\n","    ],\n","    epochs = 40,\n","          )"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["model.save(r\"C:\\Users\\rapha\\My Drive\\Work\\jedha_dsfs\\coursework\\p_final_project\\project_02\\model_checkpoints\\best_model.keras\", overwrite=False)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["model = k.models.load_model(r\"C:\\Users\\rapha\\My Drive\\Work\\jedha_dsfs\\coursework\\p_final_project\\project_02\\model_checkpoints\\model_checkpoint.keras\")"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["150/150 [==============================] - 20s 129ms/step - loss: 0.9199 - acc: 0.9316\n","Loss: 0.9199\n","Accuracy: 0.9316\n"]}],"source":["loss, acc = model.evaluate(validation_generator)\n","\n","print(f\"Loss: {loss:.4f}\")\n","print(f\"Accuracy: {acc:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"data":{"text/plain":["array([[0.]], dtype=float32)"]},"execution_count":176,"metadata":{},"output_type":"execute_result"}],"source":["pred_img_path = r\"C:\\Users\\rapha\\Pictures\\Camera Roll\\Screenshot 2024-06-12 183944.png\"\n","\n","# Load the image\n","img = tf.keras.preprocessing.image.load_img(pred_img_path, target_size=(86, 86))\n","img_array = tf.keras.preprocessing.image.img_to_array(img)\n","img_array = np.expand_dims(img_array, axis=0)\n","\n","# Preprocess the image\n","img_array = preprocess_data(img_array)\n","\n","# Predict the result\n","result = model.predict(img_array)\n","\n","# Print the predicted result\n","result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DsZ_ZFHS_EYh"},"outputs":[],"source":["import plotly.express as px\n","import plotly.graph_objects as go"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":817},"executionInfo":{"elapsed":292,"status":"ok","timestamp":1718143800211,"user":{"displayName":"Raphael Rialland","userId":"15161041091141645294"},"user_tz":-120},"id":"4qVCNLn7_dXf","outputId":"d6f8c05d-1992-42cf-8cfe-62a1b63a9171"},"outputs":[{"ename":"ValueError","evalue":"All arrays must be of the same length","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[167], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mpx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43macc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m fig\u001b[38;5;241m.\u001b[39madd_trace(go\u001b[38;5;241m.\u001b[39mScatter(y\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m      3\u001b[0m fig\u001b[38;5;241m.\u001b[39mupdate_layout(height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m)\n","File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\envs\\colab\\lib\\site-packages\\plotly\\express\\_chart_types.py:264\u001b[0m, in \u001b[0;36mline\u001b[1;34m(data_frame, x, y, line_group, color, line_dash, symbol, hover_name, hover_data, custom_data, text, facet_row, facet_col, facet_col_wrap, facet_row_spacing, facet_col_spacing, error_x, error_x_minus, error_y, error_y_minus, animation_frame, animation_group, category_orders, labels, orientation, color_discrete_sequence, color_discrete_map, line_dash_sequence, line_dash_map, symbol_sequence, symbol_map, markers, log_x, log_y, range_x, range_y, line_shape, render_mode, title, template, width, height)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mline\u001b[39m(\n\u001b[0;32m    217\u001b[0m     data_frame\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    218\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure:\n\u001b[0;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m    In a 2D line plot, each row of `data_frame` is represented as vertex of\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m    a polyline mark in 2D space.\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstructor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mScatter\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\envs\\colab\\lib\\site-packages\\plotly\\express\\_core.py:2090\u001b[0m, in \u001b[0;36mmake_figure\u001b[1;34m(args, constructor, trace_patch, layout_patch)\u001b[0m\n\u001b[0;32m   2087\u001b[0m layout_patch \u001b[38;5;241m=\u001b[39m layout_patch \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m   2088\u001b[0m apply_default_cascade(args)\n\u001b[1;32m-> 2090\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstructor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m constructor \u001b[38;5;129;01min\u001b[39;00m [go\u001b[38;5;241m.\u001b[39mTreemap, go\u001b[38;5;241m.\u001b[39mSunburst, go\u001b[38;5;241m.\u001b[39mIcicle] \u001b[38;5;129;01mand\u001b[39;00m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2092\u001b[0m     args \u001b[38;5;241m=\u001b[39m process_dataframe_hierarchy(args)\n","File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\envs\\colab\\lib\\site-packages\\plotly\\express\\_core.py:1348\u001b[0m, in \u001b[0;36mbuild_dataframe\u001b[1;34m(args, constructor)\u001b[0m\n\u001b[0;32m   1346\u001b[0m         columns \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_frame\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m         args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_frame\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_frame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1349\u001b[0m         columns \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_frame\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m df_provided:\n","File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\envs\\colab\\lib\\site-packages\\pandas\\core\\frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    705\u001b[0m     )\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n","File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\envs\\colab\\lib\\site-packages\\pandas\\core\\internals\\construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\envs\\colab\\lib\\site-packages\\pandas\\core\\internals\\construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n","File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\envs\\colab\\lib\\site-packages\\pandas\\core\\internals\\construction.py:655\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    653\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    659\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    660\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"]}],"source":["fig = px.line(model.history.history, y='acc')\n","fig.add_trace(go.Scatter(y=model.history.history['val_acc']))\n","fig.update_layout(height=400, width=800)\n","fig.show()\n","\n","fig = px.line(model.history.history, y=np.log(model.history.history['loss']))\n","fig.add_trace(go.Scatter(y=np.log(model.history.history['val_loss'])))\n","fig.update_layout(height=400, width=800)\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Assuming you have a test dataset and labels named `test_images` and `test_labels`\n","\n","validation_labels = validation_generator.classes\n","\n","# Make predictions on the test dataset\n","predictions = model.predict(validation_generator)"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[2586 2650]\n"," [2214 2150]]\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Convert predictions to class labels (assuming binary classification)\n","# predicted_labels = np.argmax(predictions, axis=1)\n","\n","# Import the confusion_matrix function from sklearn.metrics\n","from sklearn.metrics import confusion_matrix\n","\n","# Calculate the confusion matrix\n","cm = confusion_matrix(predicted_labels, validation_labels)\n","\n","# Print the confusion matrix\n","print(cm)\n","\n","# Import the seaborn library for plotting\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Plot the confusion matrix as a heatmap\n","sns.heatmap(cm, annot=True, fmt='d')\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.show()"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["thresholder = lambda x: 1 if x > 0.5 else 0\n","# predicted_labels = predictions.apply_along_axis(lambda x: 1 if x > 0.5 else 0)\n","predictions\n","\n","predicted_labels = np.array([thresholder(x) for x in predictions])\n","# predicted_labels = np.argmax(predicted_labels, axis=0)\n","predicted_labels\n","predicted_classes = np.where(predictions > 0.5, 1, 0).flatten()"]},{"cell_type":"markdown","metadata":{},"source":["accuracy\n","confusion matrix\n","delay of predictions"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 1 0 0 0 0 1 1 1 0]\n","[0 0 0 0 0 0 0 0 0 0]\n"]}],"source":["print(predicted_labels[0:10])\n","print(validation_labels[0:10])\t"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"]}],"source":["print(validation_generator.classes[0:100])"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMQCmkQNVgdMFntFeeLP7rB","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":0}

{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:46:16.948898Z",
     "start_time": "2024-06-16T09:46:16.936875Z"
    }
   },
   "source": [
    "import cv2\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:46:17.310969Z",
     "start_time": "2024-06-16T09:46:17.297433Z"
    }
   },
   "source": [
    "IMAGE_SIZE = (86, 86)\n",
    "MODEL_INPUT_SIZE = IMAGE_SIZE + (3,)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:46:18.738414Z",
     "start_time": "2024-06-16T09:46:18.731550Z"
    }
   },
   "source": [
    "from playsound import playsound\n",
    "\n",
    "sound_path = r'C:\\Users\\rapha\\My Drive\\Work\\jedha_dsfs\\coursework\\p_final_project\\project_02\\dog.mp3'"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:46:22.135796Z",
     "start_time": "2024-06-16T09:46:19.379549Z"
    }
   },
   "source": [
    "model = k.models.load_model(r\"C:\\Users\\rapha\\My Drive\\Work\\jedha_dsfs\\coursework\\p_final_project\\project_02\\model_checkpoints\\model_checkpoint.keras\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:46:22.151789Z",
     "start_time": "2024-06-16T09:46:22.139789Z"
    }
   },
   "source": [
    "def plot_img(img):\n",
    "    fig = px.imshow(img, width=86, height=86)\n",
    "    fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "    return fig.show()\n",
    "\n",
    "def process_img(img, image_size=IMAGE_SIZE, model_input_size=MODEL_INPUT_SIZE):\n",
    "    \n",
    "    def reshape_img(img, image_size=IMAGE_SIZE, model_input_size=MODEL_INPUT_SIZE):\n",
    "        img = cv2.resize(img, image_size)\n",
    "        img = img.reshape(model_input_size)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    return reshape_img(img)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T09:46:26.117388Z",
     "start_time": "2024-06-16T09:46:26.095864Z"
    }
   },
   "source": [
    "# banner image\n",
    "banner_image = cv2.imread(r\"C:\\Users\\rapha\\My Drive\\Work\\jedha_dsfs\\coursework\\p_final_project\\project_02\\banner_wake_up.jpg\")\n",
    "banner_size = (150, 150)\n",
    "banner_image = cv2.resize(banner_image, banner_size)\n",
    "\n",
    "banner_gray = cv2.cvtColor(banner_image, cv2.COLOR_BGR2GRAY)\n",
    "_, mask = cv2.threshold(banner_gray, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# video params and initialize variables\n",
    "frame_rate = 9\n",
    "pred_buffer_short = []\n",
    "prev = 0\n",
    "seconds_between_sounds = 5\n",
    "seconds_between_images = 0.2\n",
    "last_image = 0\n",
    "last_sound = 0\n",
    "\n",
    "# prediction params\n",
    "pred_buffer = []\n",
    "long_buffer_depth_ratio = 3 # buffer depth in seconds\n",
    "short_buffer_depth_ratio = 1\n",
    "long_buffer_depth = int(round(frame_rate * long_buffer_depth_ratio))\n",
    "short_buffer_depth = long_buffer_depth - int(round(frame_rate * short_buffer_depth_ratio))\n",
    "\n",
    "pred_threshold = 0.2"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# read the haarcascade to detect the faces, eyes and mouth in an image\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "mouth_cascade = cv2.CascadeClassifier()\n",
    "\n",
    "# get video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Time profiling\n",
    "# start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    #Start time of iteration\n",
    "    time_elapsed = time.time() - prev\n",
    "    \n",
    "    # Capture frame by frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Only process on x frames per second\n",
    "    if time_elapsed > 1./frame_rate:\n",
    "        # profile\n",
    "        # cascade_start_time = time.time()\n",
    "        \n",
    "        # last frame time\n",
    "        prev = time.time()\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Extract face using cascade\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        \n",
    "        # Get face img by coords\n",
    "        for (x, y, w, h) in faces:\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "            \n",
    "            # Get eye coords from face\n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "            \n",
    "            # Get eye img by coors\n",
    "            for (ex, ey, ew, eh) in eyes:\n",
    "                eye_img = roi_color[ey:ey+eh, ex:ex+ew]\n",
    "                \n",
    "                # profile\n",
    "                # cascade_end_time = time.time()\n",
    "                # print(f\"Cascade time: {cascade_end_time - cascade_start_time}\")\n",
    "                \n",
    "                # Process eye img for prediction\n",
    "                predictable_eye = process_img(eye_img)\n",
    "                # plot_img(eye_img)\n",
    "                \n",
    "                # Predict on eye, append to result to list\n",
    "                # predict_start = time.time()\n",
    "                prediction = model.predict(predictable_eye, verbose=0)\n",
    "                # predict_end = time.time()\n",
    "                # print(f\"Prediction time: {predict_end - predict_start}\")\n",
    "                \n",
    "                if prediction[0][0] > 0:\n",
    "                    pred_buffer.append(False)\n",
    "                else:\n",
    "                    pred_buffer.append(True)\n",
    "                \n",
    "                # If buffer is full, remove oldest element\n",
    "                if len(pred_buffer) > long_buffer_depth:\n",
    "                    pred_buffer.pop(0)\n",
    "                    \n",
    "                # Print overall prediction\n",
    "                # clear_output(wait=True)\n",
    "                # print(np.mean(pred_buffer))\n",
    "                \n",
    "            # if the short buffer is not completely full of false results\n",
    "            if np.sum(pred_buffer[short_buffer_depth:]) != 0:\n",
    "                # if the long buffer threshold is met, OR the short buffer is full of positives\n",
    "                if (np.mean(pred_buffer) > pred_threshold) |\\\n",
    "                    (np.mean(pred_buffer[short_buffer_depth:]) == 1):\n",
    "                    # then you are sleepy\n",
    "                    drowsy = True\n",
    "                else:\n",
    "                    drowsy = False\n",
    "            else:\n",
    "                drowsy = False\n",
    "                        \n",
    "            if drowsy:\n",
    "                print(\"You're falling asleep!\")\n",
    "                # print(pred_buffer[::-1])\n",
    "                clear_output(wait=True)\n",
    "                # if (time.time() - last_image) > seconds_between_images:\n",
    "                # set roi where to add banner image\n",
    "                roi_b = frame[-banner_size[1]-10:-10, -banner_size[0]-10:-10]\n",
    "                roi_b[np.where(mask)] = 0\n",
    "                roi_b += banner_image\n",
    "                last_image = time.time()\n",
    "                \n",
    "                # play sound\n",
    "                # if (time.time() - last_sound) > seconds_between_sounds:\n",
    "                #     playsound(sound_path)\n",
    "                #     last_sound = time.time()\n",
    "                    \n",
    "            if drowsy is not True:\n",
    "                clear_output()\n",
    "                    \n",
    "        cv2.imshow(\"Webcam\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "execution_count": 9,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
